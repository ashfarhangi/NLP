# -*- coding: utf-8 -*-
"""NLP_Assignment.ipynb

Automatically generated by Colaboratory.
"""

import pickle
import glob
import pandas as pd
import matplotlib.pyplot as plt
from tqdm import tqdm
path = '/content/drive/MyDrive/Colab Notebooks/NLP_General/data/nlp_assignment/*.bin'

files = glob.glob(path)
signal_label = []
# signal_X = []
signal_X = np.empty((1,1))
for f in files:
    with open(f, 'rb') as fp:
        signal = pickle.load(fp)
        signal = np.asarray(signal)
        signal_X = np.append(signal_X,signal)
        for j in range(len(signal)):
          # b = np.array(signal[j])
          # b = b.reshape(-1,1)
          # signal_X = np.concatenate((signal_X,b))
          signal_label.append(f[-5])
        print ('First sample of the file:',f, signal[0])
signal_X = signal_X[1:]

print(len(signal_X))
print(len(signal_label))

signal_X  = signal_X.reshape(-1,1)
signal_label = np.asarray(signal_label).reshape(-1,1)

'''
Class mappings
Map ={
    0 - 3
    1 - 4
    2 - 5
    3 - 1
    4 - 2
}
'''

X_all_new = np.zeros((1,400))

X = X_all[j][0]

X_all = X_all.reshape(-1,1,1)
for j in range(len(X_all)):
  b= np.array(X_all[j][0]).reshape(-1,1)
  X_all[j] = np.array(b)

X_all = X_all.reshape(-1,1,1)

X_all

X_all = signal_X
y_all = signal_label
y_all = np.asarray(y_all).astype('float32')

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X_all, y_all, test_size=0.3,random_state=47)

import random
import numpy as np
M = [[random.random() for n in range(random.randint(0,m))] for m in range(10000)] # play-data

def pad_to_dense(M):
    """Appends the minimal required amount of zeroes at the end of each 
     array in the jagged array `M`, such that `M` looses its jagedness."""
    maxlen = max(len(r) for r in M)

    Z = np.zeros((len(M), maxlen))
    for enu, row in enumerate(M):
        Z[enu, :len(row)] += row 
    return Z
pad_to_dense(M)

"""# Classification"""

import tensorflow as tf
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report

class ModelEvaluator:
    def make_predictions(self, model, X_data, threshold=0.5):
        Y_pred = model.predict(X_data)
        Y_pred = Y_pred > threshold
        return Y_pred

    def compute_confusion_matrix(self, Y_test, Y_pred):
        con_mat = tf.math.confusion_matrix(labels=Y_test, predictions=Y_pred).numpy()
        con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)
        return con_mat_norm

    def subplot_confusion_matrix(self, confusion_matrix, subplot_title='',
                                 subplot_index=1, subplot_rows=1, subplot_cols=1):
        np_confusion_matrix = np.array([np.array(r).astype('float') for r in confusion_matrix])

        np_confusion_matrix = np.around(np_confusion_matrix.astype('float') /
                                        np_confusion_matrix.sum(axis=1)[:, np.newaxis], decimals=2)

        # label_names = ['Bad', 'Good']
        label_names = ['0', '1','2','3','4','5','6','7','8','9']

        df_confusion_matrix = pd.DataFrame(confusion_matrix,
                                        index=label_names, 
                                        columns=label_names)

        ax = plt.subplot(subplot_rows, subplot_cols, subplot_index)
        sns.heatmap(df_confusion_matrix, cmap=plt.cm.Blues, annot=True)
        if subplot_title != '':
            ax.set_title(subplot_title)
        
        plt.ylabel('True label')
        plt.xlabel('Predicted label')

import os
import sys
import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow.keras.layers import Bidirectional, Dense, LSTM, Input, Dropout, Concatenate

from sklearn.model_selection import train_test_split
from sklearn.utils import class_weight
import ModelLoader
import ModelEvaluator
import AttentionLayer as Attention
def create_model(input_length, metrics, hidden_size=128):
    input_layer = Input(shape=(input_length, 1), name='encoder_inputs')

    lstm_layer, forward_h, forward_c, backward_h, backward_c = Bidirectional(LSTM(
            hidden_size,
            dropout=0.1,
            return_sequences=True,
            return_state=True), name='bi_lstm')(input_layer)
    
    state_h = Concatenate()([forward_h, backward_h])
    state_c = Concatenate()([forward_c, backward_c])
    context_vector, attention_weights = Attention()(lstm_layer, state_h)
    
    dense_layer = Dense(64, activation='relu')(context_vector)
    output_layer = Dense(1, activation='sigmoid')(context_vector)

    model = tf.keras.Model(inputs=input_layer, outputs=output_layer)
    
    model.compile(optimizer=tf.keras.optimizers.Adam(),
                  loss=tf.keras.losses.BinaryCrossentropy(),
                  # loss=tf.keras.losses.categorical_crossentropy,
                  metrics=metrics)

    return model
X_train = X_train.reshape(-1,X_train.shape[1],1)
X_test = X_test.reshape(-1,X_train.shape[1],1)

METRICS = [
    tf.keras.metrics.BinaryAccuracy(name='accuracy'),
    tf.keras.metrics.Precision(name='precision'),
    tf.keras.metrics.Recall(name='recall'),
    tf.keras.metrics.AUC(name='auc'),
    # tfa.metrics.F1Score(num_classes=10)
]

# Length of each audio sequence
INPUT_LENGTH = X_train.shape[1]

model = create_model(INPUT_LENGTH, METRICS)

print(model.summary())

a  = X_all
l = np.array([len(a[i]) for i in range(len(a))])
width = l.max()
b=[]
for i in range(len(a)):
    if len(a[i]) != width:
        x = np.pad(a[i], (0,width-len(a[i])), 'constant',constant_values = 0)
    else:
        x = a[i]
    b.append(x)
b = np.array(b)
print(b)
b

EPOCHS = 100


history = model.fit(X_train,
                    Y_train,
                    epochs=EPOCHS,
                    validation_data=(X_test, Y_test),
                    verbose=1)

model_evaluator = ModelEvaluator()
Y_test_1 = Y_test > 0.5
Y_pred = model_evaluator.make_predictions(model, X_test,threshold=0.8)
print(classification_report(Y_test_1,Y_pred))